{"cells":[{"cell_type":"markdown","source":["### PitchTrack for Computer Vision (CS-GY 6643) Final Project Report\n","Ahhyun Moon am12180@nyu.edu\n","Chase Huang jh9173@nyu.edu\n","Yukai Xue yx3254@nyu.edu\n","Ziyi Wang zw3917@nyu.edu"],"metadata":{"id":"4t78WO0BAx3p"}},{"cell_type":"markdown","metadata":{"id":"uK-2RF_NAwM0"},"source":["# 0. Video and Paras\n","1. Video = \"ProjectVideos/1.mp4\" [ \"ProjectVideos/1_x0.5.mp4\" ]\n","roi = (350, 50, 150, 150)\n","paras = [1.2,10,200,10,3,8]\n","\n","2. Video = \"ProjectVideos/2.mp4\" [ \"ProjectVideos/2_x0.5.mp4\" ]\n","roi = (700, 280, 800, 500)\n","paras1 = [1.5,150,45,33,11,15]\n","paras2 = [1.,30,200,10,13,15]\n","\n","3. Video = \"ProjectVideos/3_curveball.mp4\"\n","roi = (410, 100, 120, 120)\n","paras = [1.5,10,200,11,4,10]\n","\n","4. Video = \"ProjectVideos/4_4_seam_fastball.mp4\"\n","roi = (320, 80, 150, 150)\n","paras = [1.5,10,200,11,4,8]\n","\n","5. Video = \"ProjectVideos/5_change_up.mp4\"\n","roi = (330, 65, 150, 150)\n","paras = [1.5,10,200,18,2,10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fICd6NeHAwM2"},"outputs":[],"source":["roi_1 = (350, 50, 150, 150)  #(x_start, y_start, width, height)\n","paras_1=[1.2,10,200,10,3,8] # e.g. dp=1, minDist=20, param1 = 200, param2 = 11, minRadius=6,maxRadius=10)\n","path_1 = \"ProjectVideos//1.mp4\"\n","\n","roi_2 = (700, 280, 800, 500)  #(x_start, y_start, width, height)\n","paras_2_1=[1.5,150,45,33,11,15] # e.g. dp=1, minDist=20, param1 = 200, param2 = 11, minRadius=6,maxRadius=10)\n","paras_2_2=[1.,30,200,10,13,15]\n","path_2 = \"ProjectVideos\\\\2_x0.5.mp4\"\n","outpath_2 = \"4_4_seam_fastball_result.mp4\"\n","\n","roi_3 = (410, 100, 120, 120)  #(x_start, y_start, width, height)\n","paras_3=[1.5,10,200,11,4,10]  # e.g. dp=1, minDist=20, param1 = 200, param2 = 11, minRadius=6,maxRadius=10)\n","path_3 = \"ProjectVideos/3.mp4\"\n","outpath_3 = \"4_4_seam_fastball_result.mp4\"\n","\n","roi_4 = (320, 80, 150, 150)  #(x_start, y_start, width, height)\n","paras_4=[1.5,10,200,11,4,8] # e.g. dp=1, minDist=20, param1 = 200, param2 = 11, minRadius=6,maxRadius=10)\n","path_4 = \"ProjectVideos/4.mp4\"\n","outpath_14 = \"4_4_seam_fastball_result.mp4\"\n","\n","roi_5 = (330, 65, 150, 150)  #(x_start, y_start, width, height)\n","paras_5=[1.5,10,200,18,2,10] # e.g. dp=1, minDist=20, param1 = 200, param2 = 11, minRadius=6,maxRadius=10)\n","path_5 = \"ProjectVideos/5.mp4\"\n","outpath_5 = \"4_4_seam_fastball_result.mp4\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7cohUaxAwM3"},"outputs":[],"source":["rois=[roi_1,roi_2,roi_3,roi_4,roi_5]\n","parass=[paras_1,paras_2_1,paras_3,paras_4,paras_5]\n","vids=[path_1,path_2,path_3,path_4,path_5]"]},{"cell_type":"markdown","metadata":{"id":"algpx4-xAwM3"},"source":["# 1. Baseball Detection : Hough Circle Transform"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLWA2e7JAwM3"},"outputs":[],"source":["#Project Version: Frame in, Positions out\n","\n","#cap = cv2.VideoCapture(\"baseball pitch5_0.5.mp4\")\n","#fgbg = cv2.createBackgroundSubtractorMOG2()\n","#ret, frame = cap.read()\n","\n","import cv2\n","import numpy as np\n","\n","def object_detection(frame,roi,paras,sub_on,fgbg=None):\n","    if sub_on:\n","        fgmask = fgbg.apply(frame)\n","        foreground = cv2.bitwise_and(frame, frame, mask=fgmask)\n","        frame = foreground\n","\n","    #ROI example:(550, 50, 570, 320)\n","    x_start, y_start, width, height = roi\n","\n","    # Crop to the ROI\n","    roi_frame = frame[y_start:y_start+height, x_start:x_start+width]\n","\n","    # Convert to grayscale\n","    gray = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply Gaussian blur\n","    blurred = cv2.GaussianBlur(gray, (7, 7), 1)\n","\n","    # Apply thresholding for pixels close to white\n","    _, thresh = cv2.threshold(blurred, 130, 255, cv2.THRESH_BINARY)\n","\n","    # Perform Canny edge detection\n","    edges = cv2.Canny(thresh, 100, 200)\n","\n","    # Apply Hough Circle Transform\n","    circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, dp=paras[0], minDist=paras[1],\n","                               param1=paras[2], param2=paras[3], minRadius=paras[4], maxRadius=paras[5])\n","\n","    if circles is not None:\n","        circles = np.round(circles[0, :]).astype(\"int\")\n","        for i in range(len(circles)):\n","            # Adjust coordinates to map back to original frame\n","            (x,y,r) = circles[i]\n","            circles[i] = (x + x_start, y + y_start, r)\n","    # print(circles)\n","\n","    return(circles)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LS9GHD3CAwM3"},"outputs":[],"source":["def draw_circles(origin,frame,roi,paras):\n","    x_start, y_start, width, height = roi\n","\n","    # Crop to the ROI\n","    roi_frame = frame[y_start:y_start+height, x_start:x_start+width]\n","\n","    # Convert to grayscale\n","    gray = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply Gaussian blur\n","    blurred = cv2.GaussianBlur(gray, (7, 7), 1)\n","\n","    # Apply thresholding for pixels close to white\n","    _, thresh = cv2.threshold(blurred, 130, 255, cv2.THRESH_BINARY)\n","\n","    # For thicker edges\n","    # dilate = cv2.dilate(thresh, None, iterations=1)\n","\n","    # Perform Canny edge detection - Not necessary as it is part of cv2.HoughCircles\n","    edges = cv2.Canny(thresh, 100, 200)\n","\n","    # Apply Hough Circle Transform\n","    circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, dp=paras[0], minDist=paras[1],\n","                               param1=paras[2], param2=paras[3], minRadius=paras[4], maxRadius=paras[5])\n","\n","    if circles is not None:\n","        circles = np.round(circles[0, :]).astype(\"int\")\n","        for (x, y, r) in circles:\n","            cv2.circle(origin, (x + x_start, y + y_start), r, (0, 0, 255), 3)\n","\n","    cv2.rectangle(origin, (x_start, y_start), (x_start + width, y_start + height), (255, 0, 0), 3)\n","\n","    return origin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5PVMnz1AwM3"},"outputs":[],"source":["def object_detection_save(inpath,outpath,roi,paras,sub_on):\n","    cap = cv2.VideoCapture(inpath)\n","    fgbg = cv2.createBackgroundSubtractorMOG2()\n","\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","    out = cv2.VideoWriter(outpath, fourcc, fps, (frame_width, frame_height))\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        if sub_on:\n","            fgmask = fgbg.apply(frame)\n","            foreground = cv2.bitwise_and(frame, frame, mask=fgmask)\n","            processed_frame = draw_circles(frame,foreground,roi,paras)\n","        else:\n","            processed_frame = draw_circles(frame,frame,roi,paras)\n","\n","        out.write(processed_frame)\n","    cap.release()\n","    out.release()\n","\n","def object_detection_show(inpath,roi,paras,sub_on):\n","    cap = cv2.VideoCapture(inpath)\n","    fgbg = cv2.createBackgroundSubtractorMOG2()\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        if sub_on:\n","            fgmask = fgbg.apply(frame)\n","            foreground = cv2.bitwise_and(frame, frame, mask=fgmask)\n","            processed_frame = draw_circles(frame,foreground,roi,paras)\n","        else:\n","            processed_frame = draw_circles(frame,frame,roi,paras)\n","\n","        cv2.imshow('Detected Circles', processed_frame)\n","        cv2.waitKey(10) #10 millisecond buffer\n","        if 0xFF == ord('q'):\n","            break\n","\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1L7EPVkAwM4"},"outputs":[],"source":["## Example Usage\n","roi = (320, 80, 150, 150)  #(x_start, y_start, width, height)\n","paras=[1.5,10,200,11,4,8] # e.g. dp=1, minDist=20, param1 = 200, param2 = 11, minRadius=6,maxRadius=10)\n","path = \"4_4_seam_fastball_result.mp4\"\n","outpath = \"4_4_seam_fastball_result.mp4\"\n","\n","object_detection_save(path,outpath,roi,paras,True)\n"]},{"cell_type":"markdown","metadata":{"id":"4dOmp9LTAwM4"},"source":["# 2.Object Tracking : Kalman Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_Y7egLFAwM4"},"outputs":[],"source":["# !pip install filterpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cecjQRJVAwM4"},"outputs":[],"source":["from filterpy.kalman import KalmanFilter\n","from scipy.optimize import linear_sum_assignment\n","def initialize_kalman():\n","    kf = KalmanFilter(dim_x=4, dim_z=2)\n","    dt = 1.0  # time gap\n","\n","    #  transition matrix\n","    kf.F = np.array([[1, 0, dt, 0],\n","                     [0, 1, 0, dt],\n","                     [0, 0, 1, 0],\n","                     [0, 0, 0, 1]])\n","\n","    #  measurement matrix\n","    kf.H = np.array([[1, 0, 0, 0],\n","                     [0, 1, 0, 0]])\n","\n","    kf.P *= 1000.  #  initial state covariance\n","    kf.R = np.eye(2) * 10  # measurement noise\n","    kf.Q = np.eye(4) * 0.1  # process noise\n","\n","    # dictionary containing the initialized Kalman filter instance\n","    return {'kf': kf, 'missed_count': 0, 'history': []}\n","\n","def compute_iou(boxA, boxB):\n","    ## Compute the intersection over union of two boxes\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","\n","    interArea = max(0, xB - xA) * max(0, yB - yA)\n","\n","    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n","    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n","\n","    iou = interArea / float(boxAArea + boxBArea - interArea)\n","    return iou\n","\n","def compute_cost_matrix(detections, trackers,adjusted_boxes_resized):\n","    ## coumpute cost matrix for assign detection to trackers\n","    cost_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)\n","    for d, det in enumerate(detections):\n","        for t, trk in enumerate(trackers):\n","            if 'last_box' in trk:\n","                iou = compute_iou(adjusted_boxes_resized[d], trk['last_box'])\n","                cost_matrix[d, t] = 1 - iou\n","            else:\n","                cost_matrix[d, t] = np.linalg.norm(np.array(det[:2]) - np.array(trk['kf'].x[:2].reshape(-1)))\n","    return cost_matrix\n","\n","def assign_detections_to_trackers(detections, trackers,adjusted_boxes_resized):\n","    ## assign detection to trackers using hungarian algorithm\n","    cost_matrix = compute_cost_matrix(detections, trackers,adjusted_boxes_resized)\n","    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n","    return row_ind, col_ind, cost_matrix\n","\n","def update_trackers(trackers, adjusted_boxes_resized, row_ind, col_ind):\n","    matched_indices = set(row_ind)\n","    matched_trackers = set(col_ind)\n","    print(adjusted_boxes_resized)\n","    detections = [[(box[0] + box[2]) / 2, (box[1] + box[3]) / 2] for box in adjusted_boxes_resized]\n","\n","    # update the existing trackers\n","    for d, t in zip(row_ind, col_ind):\n","        trk = trackers[t]\n","        det = detections[d]\n","        trk['kf'].update(np.array([[det[0]], [det[1]]]))  # update karlman filter\n","        trk['missed_count'] = 0  #  reset missed_count\n","        # trk['last_box'] = adjusted_boxes_resized[d]\n","\n","    # Evaluate whether to create a tracker for unassociated detections\n","    for d in range(len(detections)):\n","        if d not in matched_indices:\n","            det = detections[d]\n","            should_create_new_tracker = True\n","            if should_create_new_tracker:\n","                kf = initialize_kalman()\n","                kf['kf'].update(np.array([[det[0]], [det[1]]]))\n","                new_tracker = {\n","                    'kf': kf['kf'],\n","                    'missed_count': 0,\n","                    # 'last_box':adjusted_boxes_resized[d],\n","                    'history': [(int(det[0]), int(det[1]))],\n","                }\n","                trackers.append(new_tracker)\n","\n","    # Increase the missed_count for unassigned trackers\n","    for t, trk in enumerate(trackers):\n","        if t not in matched_trackers:\n","            trk['missed_count'] += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwSFCtGxAwM4"},"outputs":[],"source":["import cv2\n","import imageio\n","from PIL import Image\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8wlV5v_AwM4"},"outputs":[],"source":["def visualize_frame(frame,trackers):\n","    ## Visualize trace and detection boxes\n","    for trk in trackers:\n","        if 'history' in trk:\n","            for pt in trk['history'][-50:]:  # Use 50 history point to represent the trace\n","                cv2.circle(frame, pt, 4, (150, 123, 238), -1)\n","                # cv2.circle(frame, pt, 8, (150, 123, 238), -1)\n","\n","        # Plot the predict points in red\n","        pred_x, pred_y = int(trk['kf'].x[0]), int(trk['kf'].x[1])\n","        cv2.circle(frame, (pred_x, pred_y), 6, (255, 0, 0), -1)\n","        # cv2.circle(frame, (pred_x, pred_y), 10, (255, 0, 0), -1)\n","\n","    return frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IeddwV52AwM5","outputId":"b355ce00-12b3-4f58-c9c9-06b4cd68c000"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[494, 193, 508, 207], [494, 178, 508, 192], [481, 185, 499, 203]]\n","[[424, 175, 434, 185]]\n","[[424, 175, 434, 185]]\n","[[427, 161, 439, 173]]\n","[[433, 150, 443, 160]]\n","[[431, 150, 441, 160]]\n","[[433, 150, 443, 160]]\n","[[437, 142, 445, 150]]\n","[[437, 142, 445, 150]]\n","[[441, 136, 449, 144]]\n","[[442, 128, 454, 140]]\n","[[442, 128, 454, 140]]\n","[[442, 128, 454, 140]]\n","[[445, 123, 457, 135]]\n","[[445, 123, 457, 135]]\n","[[447, 120, 459, 132]]\n","[[451, 123, 461, 133]]\n","[[449, 123, 459, 133]]\n","[[449, 123, 459, 133]]\n","[[451, 123, 463, 135]]\n","[[452, 125, 460, 133]]\n","[[454, 127, 464, 137]]\n","[[454, 132, 464, 142]]\n","[[453, 132, 465, 144]]\n","[[453, 132, 465, 144]]\n","[[454, 138, 466, 150]]\n","[[454, 138, 466, 150]]\n","[[454, 147, 466, 159]]\n","[[454, 156, 466, 168]]\n","[[454, 156, 466, 168]]\n","[[454, 156, 464, 166]]\n","[[456, 170, 464, 178]]\n","[[456, 170, 464, 178]]\n","[[454, 183, 464, 193]]\n","[[454, 196, 464, 206]]\n","[[454, 196, 464, 206]]\n","[[454, 196, 464, 206]]\n","[[453, 182, 465, 194]]\n","[[455, 183, 465, 193]]\n","[[455, 183, 465, 193]]\n","[[455, 183, 465, 193]]\n"]}],"source":["## Params\n","i=2\n","cap=cv2.VideoCapture(vids[i])   # video\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","fps = 20\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out_path=\"Results/5.mp4\"\n","out = cv2.VideoWriter(out_path, fourcc, fps, (frame_width, frame_height))\n","\n","roi = rois[i] # region of interest for object detection (x_start, y_start, width, height)\n","paras=parass[i]\n","fgbg = cv2.createBackgroundSubtractorMOG2()\n","# print(vids[i])\n","# print(roi)\n","# print(paras)\n","\n","trackers = []\n","frame_count=0\n","\n","## Perform object detection and traking in video\n","while True:\n","    ret, frame = cap.read()\n","    frame_count+=1\n","    if not ret:\n","        break\n","\n","    pos = object_detection(frame,roi,paras,True,fgbg)\n","    if pos is not None:\n","            # pos_count=pos_count+1\n","            # print(pos)\n","            bbox=[]\n","            for i in pos:\n","                (x, y, r) = i\n","                bbox.append([x - r, y - r, x + r, y + r])\n","            #     cv2.circle(frame, (x, y), r, (0, 0, 255), 3)\n","            detections = [[i[0],i[1]] for i in pos]\n","\n","            # print(detections)\n","            row_ind, col_ind, _ = assign_detections_to_trackers(detections, trackers,detections)\n","            update_trackers(trackers, bbox,row_ind, col_ind)\n","    else:\n","        # if frame_count>150 and frame_count<200:\n","        if frame_count>30:\n","            frame = visualize_frame(frame, tracker_last)\n","        out.write(frame)\n","        continue\n","    for trk in trackers:\n","        trk['kf'].predict()\n","        pred_x, pred_y = int(trk['kf'].x[0]), int(trk['kf'].x[1])\n","        trk['history'].append((pred_x, pred_y))  # Update history\n","\n","    trackers = [trk for trk in trackers if trk['missed_count'] < 10]\n","    tracker_last=trackers\n","    vis_frame = visualize_frame(frame, trackers)\n","    cv2.imwrite(\"test.jpg\",vis_frame)\n","    out.write(vis_frame)\n","out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DNsRlheUAwM5"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}